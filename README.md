# Swarm RL

Can swarm optimization improve upon Deep Q-learning in a classic RL problem? If so, which variation?

## Cart and Pole

* Tradtional Q-learning
* Traditional PSO
* MS-PSO (Chow & Tsui)
* MLPS (Wang, Yang & Chen) 
* DMS-PSO (Liang & Suganthan)
* SRL-PSOs (Iima & Kuroe)

## Tuning enhancements

* Gridsearch & RandomSearch for PSO tuning
* PPSO (Nobiile, Pasi & Cazzaniga)

## Questions

* What about the nature of this project would lead us to suspect one method over another?
* Why might we be seeing the performance we're seeing?
* Are our metrics effectively capturing the learning rate/timecourse of learning?
* What other RL problems 
